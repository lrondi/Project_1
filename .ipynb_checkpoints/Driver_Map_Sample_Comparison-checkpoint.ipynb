{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "import sys\n",
    "from Bio import Entrez\n",
    "\n",
    "from scipy.stats import chisquare\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import pearsonr, spearmanr, f_oneway, ttest_ind\n",
    "\n",
    "\n",
    "#import SeabornFig2Grid as sfg\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2655\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2656\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2657\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'target'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4498eb622de4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdriver_map_data_all_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DriverMapTPM.tsv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdriver_map_data_all_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver_map_data_all_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# columns:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#['A10', 'A11', 'A12', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9',\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# 'B10', 'B11', 'B12', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B9']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mset_index\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   4176\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4177\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4178\u001b[1;33m                 \u001b[0mlevel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4179\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4180\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mdrop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2926\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2927\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\PythonData\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2656\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2657\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2658\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2659\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'target'"
     ]
    }
   ],
   "source": [
    "driver_map_data_all_df = pd.read_csv('DriverMapTPM.tsv',delimiter='\\t')\n",
    "driver_map_data_all_df = driver_map_data_all_df.set_index('target')\n",
    "# columns: \n",
    "#['A10', 'A11', 'A12', 'A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', \n",
    "# 'B10', 'B11', 'B12', 'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B9']\n",
    "\n",
    "# subtract values of negative control from all samples\n",
    "# not the most pyrhonic way, meh...\n",
    "driver_map_data_all_df['A2'] = (driver_map_data_all_df['A2']-driver_map_data_all_df['A12'])\n",
    "driver_map_data_all_df['A3'] = (driver_map_data_all_df['A3']-driver_map_data_all_df['A12'])\n",
    "driver_map_data_all_df['A4'] = (driver_map_data_all_df['A4']-driver_map_data_all_df['A12'])\n",
    "driver_map_data_all_df['A5'] = (driver_map_data_all_df['A5']-driver_map_data_all_df['A12'])\n",
    "driver_map_data_all_df['A6'] = (driver_map_data_all_df['A6']-driver_map_data_all_df['A12'])\n",
    "driver_map_data_all_df['A7'] = (driver_map_data_all_df['A7']-driver_map_data_all_df['A12'])\n",
    "driver_map_data_all_df['A8'] = (driver_map_data_all_df['A8']-driver_map_data_all_df['A12'])\n",
    "driver_map_data_all_df['A9'] = (driver_map_data_all_df['A9']-driver_map_data_all_df['A12'])\n",
    "driver_map_data_all_df['A10'] = (driver_map_data_all_df['A10']-driver_map_data_all_df['A12'])\n",
    "driver_map_data_all_df['A12'] = (driver_map_data_all_df['A11']-driver_map_data_all_df['A12'])\n",
    "\n",
    "driver_map_data_all_df['B2'] = (driver_map_data_all_df['B2']-driver_map_data_all_df['B12'])\n",
    "driver_map_data_all_df['B3'] = (driver_map_data_all_df['B3']-driver_map_data_all_df['B12'])\n",
    "driver_map_data_all_df['B4'] = (driver_map_data_all_df['B4']-driver_map_data_all_df['B12'])\n",
    "driver_map_data_all_df['B5'] = (driver_map_data_all_df['B5']-driver_map_data_all_df['B12'])\n",
    "driver_map_data_all_df['B6'] = (driver_map_data_all_df['B6']-driver_map_data_all_df['B12'])\n",
    "driver_map_data_all_df['B7'] = (driver_map_data_all_df['B7']-driver_map_data_all_df['B12'])\n",
    "driver_map_data_all_df['B8'] = (driver_map_data_all_df['B8']-driver_map_data_all_df['B12'])\n",
    "driver_map_data_all_df['B9'] = (driver_map_data_all_df['B9']-driver_map_data_all_df['B12'])\n",
    "driver_map_data_all_df['B10'] = (driver_map_data_all_df['B10']-driver_map_data_all_df['B12'])\n",
    "driver_map_data_all_df['B12'] = (driver_map_data_all_df['B11']-driver_map_data_all_df['B12'])\n",
    "\n",
    "\n",
    "driver_map_data_all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.errstate(divide='ignore'):\n",
    "    driver_map_data_all_log_df = np.log2(driver_map_data_all_df)\n",
    "# replace negative values with 0    \n",
    "driver_map_data_all_log_df[driver_map_data_all_log_df < 0 ] = 0\n",
    "# repleca NaN values  with 0\n",
    "driver_map_data_all_log_df[driver_map_data_all_log_df.isna() ] = 0\n",
    "\n",
    "# rename column to sample names + sample_BSA\n",
    "driver_map_data_all_log_df = driver_map_data_all_log_df[['A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'A11', 'A12', \n",
    "                                                'B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B9', 'B10', 'B11', 'B12']]\n",
    "driver_map_data_all_log_df.columns = ['Brain', 'Univ Stratagene', 'Univ DriverMap','Univ Clontech', 'Univ BioChain', \n",
    "                              'Univ Rare', 'WB-Activated','WB-Disease', 'Univ ImmuneT10', 'Hemat System3', 'NegC_B67',\n",
    "                                 'Brain_BSA', 'Univ Stratagene_BSA', 'Univ DriverMap_BSA','Univ Clontech_BSA', 'Univ BioChain_BSA', \n",
    "                              'Univ Rare_BSA', 'WB-Activated_BSA','WB-Disease_BSA', 'Univ ImmuneT10_BSA', 'Hemat System3_BSA', 'NegC_B67_BSA']\n",
    "\n",
    "driver_map_data_all_log_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create separate file for DriverMap Original Samples\n",
    "driver_map_data_df = driver_map_data_all_df.iloc[::,]\n",
    "driver_map_data_df = driver_map_data_df[['A2', 'A3', 'A4', 'A5', 'A6', 'A7', 'A8', 'A9', 'A10', 'A11', 'A12']]\n",
    "driver_map_data_df.columns = ['Brain', 'Univ Stratagene', 'Univ DriverMap','Univ Clontech', 'Univ BioChain', \n",
    "                              'Univ Rare', 'WB-Activated','WB-Disease', 'Univ ImmuneT10', 'Hemat System3', 'NegC_B67']\n",
    "\n",
    "driver_map_data_df.reset_index(drop=False)\n",
    "driver_map_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take log2 of the original and ignote devide by 0 error message\n",
    "with np.errstate(divide='ignore'):\n",
    "    driver_map_data_log_df = np.log2(driver_map_data_df)\n",
    "\n",
    "# replace negative values with 0    \n",
    "driver_map_data_log_df[driver_map_data_log_df < 0 ] = 0\n",
    "# repleca NaN values  with 0\n",
    "driver_map_data_log_df[driver_map_data_log_df.isna() ] = 0\n",
    "\n",
    "#flip axis\n",
    "switch_driver_map_data_log_df=driver_map_data_log_df.transpose()\n",
    "\n",
    "# create heap map\n",
    "plt.figure(figsize=(20,4))\n",
    "sns.heatmap(switch_driver_map_data_log_df,xticklabels=False,yticklabels=True)\n",
    "plt.title('Heatmap for DriverMap Original Samples')\n",
    "\n",
    "switch_driver_map_data_log_df.to_csv('DM_data_log_original.csv')\n",
    "driver_map_data_log_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make DF for DriverMap for samples treated with BSA and \n",
    "driver_map_data_bsa_df = driver_map_data_all_df.iloc[::,-12:]\n",
    "driver_map_data_bsa_df = driver_map_data_bsa_df[['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B8', 'B9', 'B10', 'B11', 'B12']]\n",
    "driver_map_data_bsa_df.columns = ['Brain', 'Univ Stratagene', 'Univ DriverMap','Univ Clontech', 'Univ BioChain', \n",
    "                              'Univ Rare', 'WB-Activated','WB-Disease', 'Univ ImmuneT10', 'Hemat System3', 'NegC_B67']\n",
    "\n",
    "#driver_map_data_bsa_df.reset_index(drop=False)\n",
    "\n",
    "# convert DriverMap data into log2 functions and ignote devide by 0 error message\n",
    "with np.errstate(divide='ignore'):\n",
    "    driver_map_data_bsa_log_df = driver_map_data_bsa_df.apply(np.log2, reduce=None)\n",
    "\n",
    "# replace negative values with 0    \n",
    "driver_map_data_bsa_log_df[driver_map_data_bsa_log_df < 0 ] = 0\n",
    "# replace NaN values with 0  \n",
    "driver_map_data_bsa_log_df[driver_map_data_bsa_log_df.isna() ] = 0\n",
    "\n",
    "    \n",
    "#flip axis\n",
    "switch_driver_map_data_bsa_log_df=driver_map_data_bsa_log_df.transpose()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,4))\n",
    "sns.heatmap(switch_driver_map_data_bsa_log_df,xticklabels=False,yticklabels=True)\n",
    "plt.title('Heatmap for DriverMap BSA Samples')\n",
    "\n",
    "switch_driver_map_data_bsa_log_df.to_csv('DM_data_log_BSA.csv')\n",
    "driver_map_data_bsa_log_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_genes_split = driver_map_data_df.index.str.split('|')\n",
    "gene_name_list = [unique_genes_split[i][1] for i in range(len(unique_genes_split))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [-1,0,4,7,17]\n",
    "bin_labels = ['no read','low','medium','high']\n",
    "\n",
    "def bin_logs(df):\n",
    "    \n",
    "    # Make empty dictionary to fill with column cut in bins\n",
    "    bin_data = {}\n",
    "    # Make empty dictionary to fill with count of genes per bin\n",
    "    bin_group = {}\n",
    "    \n",
    "    for i in list(df.columns):\n",
    "        bin_data[i] = pd.cut(df[i],bins,labels=bin_labels)\n",
    "    \n",
    "    # Make temporary df with binned data\n",
    "    bin_dataf = pd.DataFrame.from_dict(bin_data)\n",
    "    \n",
    "    # Make df with counts of gene grouped by bin\n",
    "    for j in list(bin_dataf.columns):\n",
    "        gr_count = bin_dataf.groupby(j)[j].count()\n",
    "        bin_group[j] = gr_count\n",
    "    \n",
    "    return pd.DataFrame.from_dict(bin_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rearrange samples original and BSA next to yeach other on big graph\n",
    "driver_map_data_all_log_df = driver_map_data_all_log_df[['Brain', 'Brain_BSA',\n",
    "                                         'Univ Stratagene', 'Univ Stratagene_BSA',\n",
    "                                         'Univ DriverMap','Univ DriverMap_BSA',\n",
    "                                         'Univ Clontech', 'Univ Clontech_BSA',\n",
    "                                         'Univ BioChain', 'Univ BioChain_BSA',\n",
    "                                         'Univ Rare', 'Univ Rare_BSA',\n",
    "                                         'WB-Activated', 'WB-Activated_BSA',\n",
    "                                         'WB-Disease', 'WB-Disease_BSA',\n",
    "                                         'Univ ImmuneT10', 'Univ ImmuneT10_BSA',\n",
    "                                         'Hemat System3', 'Hemat System3_BSA',\n",
    "                                         'NegC_B67','NegC_B67_BSA']]\n",
    "\n",
    "binned_all_dm_data = bin_logs(driver_map_data_all_log_df)\n",
    "binned_all_dm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_dm_data = bin_logs(driver_map_data_log_df)\n",
    "binned_dm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_bsa_data = bin_logs(driver_map_data_bsa_log_df)\n",
    "binned_bsa_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,5)) \n",
    "ax1 = fig.add_subplot(1, 2, 1) \n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "sns.heatmap(binned_dm_data, cmap = 'BuPu', ax = ax1, vmin=0, vmax=11000) \n",
    "plt.setp(ax1.yaxis.get_majorticklabels(), rotation = 0)\n",
    "ax1.set_title('DriverMap_Original')\n",
    "\n",
    "sns.heatmap(binned_bsa_data, cmap = 'BuPu', ax = ax2, vmin=0, vmax=11000, cbar_kws = {'label':'Number of genes'})\n",
    "plt.setp(ax2.yaxis.get_majorticklabels(), rotation = 0)\n",
    "ax2.set_title('DriverMap_BSA')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize = (20,5)) \n",
    "ax1 = fig.add_subplot(1, 1, 1) \n",
    "\n",
    "sns.heatmap(binned_all_dm_data, cmap = 'BuPu', ax = ax1, vmin=0, vmax=11000) \n",
    "plt.setp(ax1.yaxis.get_majorticklabels(), rotation = 0)\n",
    "ax1.set_title('DriverMap_Original_and_BSA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,15))\n",
    "\n",
    "for i in range(10):\n",
    "    title_font = {'size':'20'}\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.bar(x = binned_dm_data.index, height = binned_dm_data.iloc[:,i], alpha=0.5, color='red',label='DriverMap_Original')\n",
    "    plt.bar(x = binned_bsa_data.index, height = binned_bsa_data.iloc[:,i], alpha=0.5, color='blue',label='DriverMap_BSA')\n",
    "    plt.title(binned_dm_data.columns[i],**title_font)\n",
    "    plt.xlabel('level of expression')\n",
    "    plt.ylabel('number of genes')\n",
    "    plt.ylim(0, 11500)\n",
    "    plt.legend()\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(3, 4, figsize=(15, 7), sharex=True)\n",
    "\n",
    "ax = sns.distplot( driver_map_data_log_df['Brain'] , color=\"red\", ax=axes[0, 0])\n",
    "ax = sns.distplot( driver_map_data_bsa_log_df['Brain'] , color=\"blue\", ax=axes[0, 0])\n",
    "ax = sns.distplot( driver_map_data_log_df['Univ Stratagene'] , color=\"red\", ax=axes[0, 1])\n",
    "ax = sns.distplot( driver_map_data_bsa_log_df['Univ Stratagene'] , color=\"blue\", ax=axes[0, 1])\n",
    "ax = sns.distplot( driver_map_data_log_df['Univ DriverMap'] , color=\"red\", ax=axes[0, 2])\n",
    "ax = sns.distplot( driver_map_data_bsa_log_df['Univ DriverMap'] , color=\"blue\", ax=axes[0, 2])\n",
    "ax = sns.distplot( driver_map_data_log_df['Univ Clontech'] , color=\"red\", ax=axes[0, 3])\n",
    "ax = sns.distplot( driver_map_data_bsa_log_df['Univ Clontech'] , color=\"blue\", ax=axes[0, 3])\n",
    "ax = sns.distplot( driver_map_data_log_df['Univ BioChain'] , color=\"red\", ax=axes[1, 0])\n",
    "ax = sns.distplot( driver_map_data_bsa_log_df['Univ BioChain'] , color=\"blue\", ax=axes[1, 0])\n",
    "ax = sns.distplot( driver_map_data_log_df['Univ Rare'] , color=\"red\", ax=axes[1, 1])\n",
    "ax = sns.distplot( driver_map_data_bsa_log_df['Univ Rare'] , color=\"blue\", ax=axes[1, 1])\n",
    "ax = sns.distplot( driver_map_data_log_df['WB-Activated'] , color=\"red\", ax=axes[1, 2])\n",
    "ax = sns.distplot( driver_map_data_bsa_log_df['WB-Activated'] , color=\"blue\", ax=axes[1, 2])\n",
    "ax = sns.distplot( driver_map_data_log_df['WB-Disease'] , color=\"red\", ax=axes[1, 3])\n",
    "ax = sns.distplot( driver_map_data_bsa_log_df['WB-Disease'] , color=\"blue\", ax=axes[1, 3])\n",
    "ax = sns.distplot( driver_map_data_log_df['Univ ImmuneT10'] , color=\"red\", ax=axes[2, 0])\n",
    "ax = sns.distplot( driver_map_data_bsa_log_df['Univ ImmuneT10'] , color=\"blue\", ax=axes[2, 0])\n",
    "ax = sns.distplot( driver_map_data_log_df['Hemat System3'] , color=\"red\", ax=axes[2, 1])\n",
    "ax = sns.distplot( driver_map_data_bsa_log_df['Hemat System3'] , color=\"blue\", ax=axes[2, 1])\n",
    "ax = sns.distplot( driver_map_data_log_df['NegC_B67'] , color=\"red\", ax=axes[2, 3])\n",
    "ax = sns.distplot( driver_map_data_bsa_log_df['NegC_B67'] , color=\"blue\", ax=axes[2, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another possible way to normalize data\n",
    "\n",
    "#log2df = np.log2(my_df)\n",
    "#log2mean = log2df.mean(axis='columns')\n",
    "#log_div_ave = log2df.subtract(log2mean, axis='index')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate correlation coefficient between two arrays\n",
    "def corr(x, y, **kwargs):\n",
    "    \n",
    "    # Calculate the value\n",
    "    coef = np.corrcoef(x, y)[0][1]\n",
    "    # Make the label\n",
    "    label = r'$\\rho$ = ' + str(round(coef, 2))\n",
    "    \n",
    "    # Add the label to the plot\n",
    "    ax = plt.gca()\n",
    "    ax.annotate(label, xy = (0.2, 0.95), size = 20, xycoords = ax.transAxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a pair grid instance\n",
    "grid = sns.PairGrid(data= binned_dm_data, size = 4)\n",
    "\n",
    "# Map the plots to the locations\n",
    "grid = grid.map_upper(plt.scatter, color = 'darkred')\n",
    "grid = grid.map_upper(corr)\n",
    "grid = grid.map_lower(sns.kdeplot, cmap = 'Reds')\n",
    "grid = grid.map_diag(plt.hist, bins = 10, edgecolor =  'k', color = 'darkred');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a pair grid instance\n",
    "grid = sns.PairGrid(data= binned_bsa_data, size = 4)\n",
    "\n",
    "# Map the plots to the locations\n",
    "grid = grid.map_upper(plt.scatter, color = 'darkred')\n",
    "grid = grid.map_upper(corr)\n",
    "grid = grid.map_lower(sns.kdeplot, cmap = 'Reds')\n",
    "grid = grid.map_diag(plt.hist, bins = 10, edgecolor =  'k', color = 'darkred');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a pair grid instance\n",
    "grid = sns.PairGrid(data= binned_all_dm_data, size = 4)\n",
    "\n",
    "# Map the plots to the locations\n",
    "grid = grid.map_upper(plt.scatter, color = 'darkred')\n",
    "grid = grid.map_upper(corr)\n",
    "grid = grid.map_lower(sns.kdeplot, cmap = 'Reds')\n",
    "grid = grid.map_diag(plt.hist, bins = 10, edgecolor =  'k', color = 'darkred');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a pair grid instance\n",
    "fig = plt.figure(figsize=(13,8))\n",
    "grid = sns.PairGrid(data= driver_map_data_bsa_log_df, size = 4)\n",
    "\n",
    "# Map the plots to the locations\n",
    "grid = grid.map_upper(plt.scatter, color = 'darkred')\n",
    "grid = grid.map_upper(corr)\n",
    "grid = grid.map_lower(sns.kdeplot, cmap = 'Reds')\n",
    "grid = grid.map_diag(plt.hist, bins = 10, edgecolor = 'k', color = 'darkred');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots to visualize outliers for binned data\n",
    "\n",
    "plt.figure(figsize=(20,7))\n",
    "plt.subplots\n",
    "binned_all_dm_data.boxplot()\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots to visualize outliers for log data\n",
    "# a lot more outliers\n",
    "plt.figure(figsize=(20,7))\n",
    "plt.subplots\n",
    "driver_map_data_all_log_df.boxplot()\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An Independent Samples t-test compares the means for two groups.\n",
    "\n",
    "\n",
    "The hypothesis being tested is:\n",
    "\n",
    "Null hypothesis (H0): u1 = u2, which translates to the mean of sample 1 is equal to the mean of sample 2\n",
    "Alternative hypothesis (HA): u1 ? u2, which translates to the mean of sample 1 is not equal to the mean of sample 2\n",
    "\n",
    "A p-value is the probability of rejecting a null-hypothesis when the hypothesis is proven true. The null hypothesis is a statement that says that there is no difference between two measures.\n",
    "\n",
    "We are interested in p-values below 0.05(significant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-test for binned data\n",
    "idx = binned_dm_data.index.intersection(binned_bsa_data.index)\n",
    "t_test_bins_df = pd.DataFrame(ttest_ind(binned_dm_data.loc[idx], binned_bsa_data.loc[idx], axis=1), \n",
    "                              index=['t-stat','p-value'], columns = bin_labels)\n",
    "\n",
    "#Ttest_indResult(\n",
    "#    statistic=array([-0.31240597,  0.66835531, -0.17359046, -0.21035294]), \n",
    "#    pvalue=array([0.75796591, 0.51154742, 0.86393227, 0.83552046]))\n",
    "flip_t_test_bins_df = t_test_bins_df.transpose()\n",
    "\n",
    "flip_t_test_bins_df.describe()\n",
    "t_test_bins_df\n",
    "# no real statistical difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t-test for log data\n",
    "index = ['Original', 'BSA']\n",
    "\n",
    "idx = driver_map_data_log_df.index.intersection(driver_map_data_bsa_log_df.index)\n",
    "t_test_df = pd.DataFrame(ttest_ind(driver_map_data_log_df.loc[idx], driver_map_data_bsa_log_df.loc[idx], axis=1), \n",
    "                         index=['t-stat','p-value'], columns=gene_name_list)\n",
    "flip_t_test_df = t_test_df.transpose()\n",
    "\n",
    "flip_t_test_df = [flip_t_test_df[['p-value']] < 0.05]\n",
    "#flip_t_test_df.count('False')\n",
    "flip_t_test_df = flip_t_test_df[0]\n",
    "#f = flip_t_test_df.drop([flip_t_test_df['p-value'] == False])\n",
    "\n",
    "np.sum(flip_t_test_df['p-value']) # 2829 genes have statistical significance.\n",
    "#flip_t_test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new DataFrame where the values for the indices and columns align on the diagonals\n",
    "# Pearson correlation between two samples\n",
    "\n",
    "# A value greater than 0 indicates a positive association; that is, as the value of one variable increases, \n",
    "# so does the value of the other variable.\n",
    "\n",
    "pearson_corr = pd.DataFrame(columns = driver_map_data_log_df.columns, index = driver_map_data_log_df.columns)\n",
    "\n",
    "for col in pearson_corr.columns:\n",
    "    for idx in c.index:\n",
    "        correl_signif = pearsonr(driver_map_data_log_df[col], driver_map_data_bsa_log_df[idx])\n",
    "        correl = correl_signif[0]\n",
    "        pearson_corr.loc[idx, col] = correl\n",
    "\n",
    "pearson_corr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spearman_corr = pd.DataFrame(columns = driver_map_data_log_df.columns, index = driver_map_data_log_df.columns)\n",
    "\n",
    "for col in spearman_corr.columns:\n",
    "    for idx in c.index:\n",
    "        correl_signif = spearmanr(driver_map_data_log_df[col], driver_map_data_bsa_log_df[idx])\n",
    "        correl = correl_signif[0]\n",
    "        spearman_corr.loc[idx, col] = correl\n",
    "\n",
    "spearman_corr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_corr_bins = pd.DataFrame(columns = binned_dm_data.columns, index = binned_dm_data.columns)\n",
    "\n",
    "for col in pearson_corr.columns:\n",
    "    for idx in c.index:\n",
    "        correl_signif = pearsonr(binned_dm_data[col], binned_bsa_data[idx])\n",
    "        correl = correl_signif[0]\n",
    "        pearson_corr_bins.loc[idx, col] = correl\n",
    "\n",
    "pearson_corr_bins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(binned_bsa_data, kind=\"reg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
